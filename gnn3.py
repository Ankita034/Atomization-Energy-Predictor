# -*- coding: utf-8 -*-
"""GNN3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hz9QpknAi7tRgXp9P9PrCNA2xsTF9g9S
"""

#!pip install numpy pandas matplotlib scikit-learn xgboost torch torchvision torch-geometric

#!pip install torch_geometric

# âœ… Import required libraries
import numpy as np
import pandas as pd
import scipy.io
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, precision_recall_curve, auc
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv, global_mean_pool
import pickle

# âœ… Load QM7 dataset
qm7 = scipy.io.loadmat('qm7.mat')

# âœ… Extract data
X = qm7['X']  # Coulomb matrices (7165, 23, 23)
T = qm7['T'].flatten()  # Atomization energies (7165,)

# âœ… Standardize target atomization energies
scaler = StandardScaler()
T_scaled = scaler.fit_transform(T.reshape(-1, 1)).flatten()

import joblib

# âœ… Save Scaler after fitting
joblib.dump(scaler, "scaler.pkl")
print("âœ… Scaler saved as 'scaler.pkl'")


# âœ… Flatten Coulomb matrices for XGBoost and RF
X_flat = X.reshape(X.shape[0], -1)

# âœ… Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_flat, T_scaled, test_size=0.2, random_state=42)

# âœ… Feature Selection using Correlation Matrix
correlation_threshold = 0.8
correlation_matrix = np.corrcoef(X_train.T)

# âœ… Identify highly correlated features
high_correlation_indices = set()
for i in range(len(correlation_matrix)):
    for j in range(i + 1, len(correlation_matrix)):
        if abs(correlation_matrix[i, j]) > correlation_threshold:
            high_correlation_indices.add(j)

# âœ… Remove highly correlated features
X_train = np.delete(X_train, list(high_correlation_indices), axis=1)
X_test = np.delete(X_test, list(high_correlation_indices), axis=1)

with open("high_indices.pkl", "wb") as f:
    pickle.dump(list(high_correlation_indices), f)

print(f"âœ… Selected Features: {X_train.shape[1]} after removing correlated features.")
print("âœ… high_indices.pkl saved successfully!")

print(f"âœ… Selected Features: {X_train.shape[1]} after removing correlated features.")

# âœ… XGBoost Model
xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

# âœ… Random Forest Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# âœ… Convert Coulomb matrices to graph format
def convert_to_graph(matrix):
    num_atoms = matrix.shape[0]
    edge_index = []
    edge_attr = []

    for i in range(num_atoms):
        for j in range(i + 1, num_atoms):
            if matrix[i, j] != 0:
                edge_index.append([i, j])
                edge_index.append([j, i])
                edge_attr.append(matrix[i, j])
                edge_attr.append(matrix[j, i])

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attr, dtype=torch.float).view(-1, 1)

    # Node features (diagonal of the matrix)
    x = torch.tensor(np.diag(matrix), dtype=torch.float).view(-1, 1)

    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)

# âœ… Prepare graph data
graph_data = [convert_to_graph(matrix) for matrix in X]

# âœ… Define GNN Model
class GNNModel(nn.Module):
    def __init__(self, hidden_dim=64):
        super(GNNModel, self).__init__()
        self.conv1 = GCNConv(1, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.fc1 = nn.Linear(hidden_dim, 32)
        self.fc2 = nn.Linear(32, 1)

    def forward(self, data):
        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr

        # âœ… Apply GCN layers
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        x = F.relu(x)

        # âœ… Global pooling
        x = global_mean_pool(x, data.batch)

        # âœ… Fully connected layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)

        return x.view(-1)

# âœ… Initialize and train GNN
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
gnn_model = GNNModel(hidden_dim=64).to(device)
optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# âœ… Convert atomization energy to tensor
for i, data in enumerate(graph_data):
    graph_data[i].y = torch.tensor([T_scaled[i]], dtype=torch.float)

train_loader = DataLoader(graph_data[:6000], batch_size=32, shuffle=True)
test_loader = DataLoader(graph_data[6000:], batch_size=32)

# âœ… Training Loop for GNN
for epoch in range(50):
    gnn_model.train()
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        output = gnn_model(data)
        loss = criterion(output, data.y)
        loss.backward()
        optimizer.step()

# âœ… Predict and evaluate GNN
def predict_gnn(model, loader, device):
    model.eval()
    predictions, targets = [], []
    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            output = model(data).cpu().numpy()
            predictions.extend(output)
            targets.extend(data.y.cpu().numpy())
    return np.array(predictions), np.array(targets)

# âœ… GNN Predictions
y_pred_gnn, y_true_gnn = predict_gnn(gnn_model, test_loader, device)

# âœ… Calculate Mean Squared Error for All Models
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
mse_rf = mean_squared_error(y_test, y_pred_rf)
mse_gnn = mean_squared_error(y_true_gnn, y_pred_gnn)

print(f"âœ… XGBoost MSE: {mse_xgb:.4f}")
print(f"âœ… Random Forest MSE: {mse_rf:.4f}")
print(f"âœ… GNN MSE: {mse_gnn:.4f}")

# âœ… Define a threshold to convert regression outputs to binary
threshold = np.median(y_test)

# âœ… Convert regression predictions to binary labels
y_pred_xgb_class = (y_pred_xgb >= threshold).astype(int)
y_pred_rf_class = (y_pred_rf >= threshold).astype(int)
y_pred_gnn_class = (y_pred_gnn >= threshold).astype(int)

# âœ… Convert true values to binary labels
y_test_class = (y_test >= threshold).astype(int)
y_true_gnn_class = (y_true_gnn >= threshold).astype(int)

# âœ… Updated precision-recall plotting function
def plot_precision_recall(y_true, y_pred, model_name):
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    auc_score = auc(recall, precision)
    plt.plot(recall, precision, label=f'{model_name} (AUC = {auc_score:.2f})')

# âœ… Plot Precision-Recall Curve
plt.figure(figsize=(8, 6))
plot_precision_recall(y_test_class, y_pred_xgb_class, "XGBoost")
plot_precision_recall(y_test_class, y_pred_rf_class, "Random Forest")
plot_precision_recall(y_true_gnn_class, y_pred_gnn_class, "GNN")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve for All Models")
plt.legend()
plt.show()

# âœ… Predict Atomization Energy with XGBoost and RF
y_pred_xgb = xgb_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)

# âœ… Predict Atomization Energy with GNN
y_pred_gnn, y_true_gnn = predict_gnn(gnn_model, test_loader, device)

# âœ… Calculate RÂ² Score for All Models
from sklearn.metrics import r2_score
r2_xgb = r2_score(y_test, y_pred_xgb)
r2_rf = r2_score(y_test, y_pred_rf)
r2_gnn = r2_score(y_true_gnn, y_pred_gnn)

print(f"âœ… XGBoost RÂ²: {r2_xgb:.4f}")
print(f"âœ… Random Forest RÂ²: {r2_rf:.4f}")
print(f"âœ… GNN RÂ²: {r2_gnn:.4f}")

# âœ… Plot Bar Chart of Model Accuracy (RÂ² Score)
plt.figure(figsize=(8, 6))
models = ['XGBoost', 'Random Forest', 'GNN']
r2_scores = [r2_xgb, r2_rf, r2_gnn]
plt.bar(models, r2_scores, color=['blue', 'green', 'orange'])
plt.ylabel('RÂ² Score')
plt.title('Model Accuracy Comparison (RÂ² Score)')
plt.ylim(0, 1)
plt.show()

# âœ… Predict for a Random Molecule and Check Reactivity
molecule_index = np.random.randint(0, len(graph_data))
data = graph_data[molecule_index].to(device)

# âœ… GNN Prediction
gnn_model.eval()
with torch.no_grad():
    predicted_energy = gnn_model(data).item()

predicted_energy = scaler.inverse_transform([[predicted_energy]])[0, 0]
true_energy = T[molecule_index]

# âœ… Predict Reactivity
def infer_reactivity(energy, threshold):
    return "Reactive âš¡" if energy >= threshold else "Stable ðŸ§ª"

reactivity_result = infer_reactivity(predicted_energy, np.median(T))

# âœ… Display Results
print(f"\n=== Molecule {molecule_index} ===")
print(f"ðŸ”¹ Predicted Atomization Energy: {predicted_energy:.2f} kcal/mol")
print(f"ðŸ”¹ True Atomization Energy: {true_energy:.2f} kcal/mol")
print(f"ðŸ”¹ Reactivity Status: {reactivity_result}")

from collections import Counter

# âœ… Define atomic symbols (for first 10 elements + few others for QM7)
atomic_symbols = {
    1: "H",  6: "C",  7: "N",  8: "O",  9: "F",
    16: "S", 17: "Cl", 35: "Br", 53: "I"  # Common elements in QM7 dataset
}

# âœ… Select a random molecule for prediction
molecule_index = np.random.randint(0, len(graph_data))
data = graph_data[molecule_index].to(device)

# âœ… GNN Prediction
gnn_model.eval()
with torch.no_grad():
    predicted_energy_gnn = gnn_model(data).item()

predicted_energy_gnn = scaler.inverse_transform([[predicted_energy_gnn]])[0, 0]
true_energy = T[molecule_index]

# âœ… Get XGBoost and Random Forest Predictions
X_molecule = X_flat[molecule_index].reshape(1, -1)
X_molecule_selected = np.delete(X_molecule, list(high_correlation_indices), axis=1)  # Apply feature selection

predicted_energy_xgb = scaler.inverse_transform([[xgb_model.predict(X_molecule_selected)[0]]])[0, 0]
predicted_energy_rf = scaler.inverse_transform([[rf_model.predict(X_molecule_selected)[0]]])[0, 0]

# âœ… Predict Reactivity Based on Energy Threshold
def infer_reactivity(energy, threshold):
    return "Reactive âš¡" if energy >= threshold else "Stable ðŸ§ª"

reactivity_result = infer_reactivity(predicted_energy_gnn, np.median(T))

# âœ… Generate Molecular Formula
atomic_numbers = qm7['Z'][molecule_index].astype(int)
atomic_numbers = atomic_numbers[atomic_numbers > 0]
atom_counts = Counter(atomic_numbers)

molecular_formula = "".join(
    f"{atomic_symbols[atom]}{count if count > 1 else ''}"
    for atom, count in sorted(atom_counts.items(), key=lambda x: atomic_symbols.get(x[0], ''))
)

# âœ… Display Final Results
print(f"\n=== Molecule {molecule_index} ===")
print(f"ðŸ”¹ Molecular Formula: {molecular_formula}")
print(f"ðŸ”¹ True Atomization Energy: {true_energy:.2f} kcal/mol")
print(f"ðŸ”¹ Predicted Energy (XGBoost): {predicted_energy_xgb:.2f} kcal/mol")
print(f"ðŸ”¹ Predicted Energy (Random Forest): {predicted_energy_rf:.2f} kcal/mol")
print(f"ðŸ”¹ Predicted Energy (GNN): {predicted_energy_gnn:.2f} kcal/mol")
print(f"ðŸ”¹ Reactivity Status: {reactivity_result}")


import joblib
import torch
import pickle

# âœ… Save XGBoost Model
joblib.dump(xgb_model, "xgb_model.pkl")
print("âœ… XGBoost model saved as 'xgb_model.pkl'")

# âœ… Save Random Forest Model
joblib.dump(rf_model, "rf_model.pkl")
print("âœ… Random Forest model saved as 'rf_model.pkl'")

# âœ… Save GNN Model
torch.save(gnn_model.state_dict(), "gnn_model.pth")
print("âœ… GNN model saved as 'gnn_model.pth'")

# âœ… Save Graph Data
with open("graph_data.pkl", "wb") as f:
    pickle.dump(graph_data, f)
print("âœ… Graph data saved as 'graph_data.pkl'")
